import asyncio
import json
import logging
import os
import re
import shutil
import subprocess
import uuid
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

import requests
import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse, Response, StreamingResponse
from pydantic import BaseModel

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è ANSI escape –∫–æ–¥–æ–≤
ANSI_ESCAPE_PATTERN = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')

def strip_ansi_codes(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç ANSI escape –∫–æ–¥—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    return ANSI_ESCAPE_PATTERN.sub('', text)

# =========================================================================================
# –ü–†–û–ö–°–ò –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –° –†–û–¢–ê–¶–ò–ï–ô (–∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º ProxyRotator)
# =========================================================================================
from proxy_rotator import get_proxy_rotator

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Ä–æ—Ç–∞—Ç–æ—Ä –ø—Ä–æ–∫—Å–∏
PROXY_ROTATOR = get_proxy_rotator("mangalib")
logger.info(f"Proxy rotator initialized: {PROXY_ROTATOR}")

def get_proxy_for_request() -> Optional[Dict[str, str]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–æ–∫—Å–∏ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ (—Å —Ä–æ—Ç–∞—Ü–∏–µ–π).
    –ï—Å–ª–∏ –ø—Ä–æ–∫—Å–∏ –æ–¥–∏–Ω - —Ä–æ—Ç–∞—Ü–∏—è –Ω–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç.
    –ï—Å–ª–∏ –ø—Ä–æ–∫—Å–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ - –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Ä–æ—Ç–∞—Ü–∏—è —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏.
    
    Returns:
        dict —Å –ø—Ä–æ–∫—Å–∏ {'http': '...', 'https': '...'} –∏–ª–∏ None
    """
    if PROXY_ROTATOR.get_proxy_count() == 0:
        return None
    
    # –ï—Å–ª–∏ –ø—Ä–æ–∫—Å–∏ –æ–¥–∏–Ω - –≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ–≥–æ (–±–µ–∑ —Ä–æ—Ç–∞—Ü–∏–∏)
    if PROXY_ROTATOR.get_proxy_count() == 1:
        return PROXY_ROTATOR.get_current_proxy()
    
    # –ï—Å–ª–∏ –ø—Ä–æ–∫—Å–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ - —Ä–æ—Ç–∞—Ü–∏—è –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
    return PROXY_ROTATOR.get_next_proxy()

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –ø—Ä–æ–∫—Å–∏
if PROXY_ROTATOR.enabled:
    proxy_count = PROXY_ROTATOR.get_proxy_count()
    logger.info(f"‚úÖ Proxy rotation enabled: {proxy_count} proxy(ies), strategy={PROXY_ROTATOR.rotation_strategy}")
else:
    logger.info("‚ÑπÔ∏è  No proxy configured (requests will go directly)")
# =========================================================================================

app = FastAPI()

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class ParseRequest(BaseModel):
    slug: str
    parser: str = "newtoki"

class BuildRequest(BaseModel):
    slug: str
    parser: str = "newtoki"
    type: str = "simple"

class BatchParseRequest(BaseModel):
    slugs: List[str]
    parser: str = "newtoki"
    auto_import: bool = True

class ParseStatus(BaseModel):
    task_id: str
    status: str  # pending, running, completed, failed
    progress: int
    message: str
    created_at: str
    updated_at: str
    total_slugs: int
    completed_slugs: int
    failed_slugs: int
    current_slug: Optional[str] = None
    results: List[Dict[str, Any]] = []

class BatchParseStatus(BaseModel):
    task_id: str
    status: str  # pending, running, completed, failed
    progress: int
    message: str
    created_at: str
    updated_at: str
    total_slugs: int
    completed_slugs: int
    failed_slugs: int
    current_slug: Optional[str] = None
    results: List[Dict[str, Any]] = []

class LogEntry(BaseModel):
    timestamp: str
    level: str
    message: str
    task_id: Optional[str] = None

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∑–∞–¥–∞—á (–≤ production –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Redis)
tasks_storage: Dict[str, ParseStatus] = {}

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –ª–æ–≥–æ–≤ –¥–ª—è –∑–∞–¥–∞—á
task_logs: Dict[str, List[LogEntry]] = {}

# –•—Ä–∞–Ω–∏–ª–∏—â–µ —Å–æ—Å—Ç–æ—è–Ω–∏–π –±–∏–ª–¥–∞ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
build_states: Dict[str, Dict[str, Any]] = {}  # task_id -> {"slug": str, "is_ready": bool, "files_ready": bool}

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
def get_melon_base_path() -> Path:
    return Path("/app")

def ensure_utf8_patch():
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ç—á –¥–ª—è UTF-8 –∫–æ–¥–∏—Ä–æ–≤–∫–∏"""
    dublib_path = get_melon_base_path() / "dublib" / "Methods" / "Filesystem.py"

    if dublib_path.exists():
        content = dublib_path.read_text(encoding='utf-8')
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ –ø–∞—Ç—á
        if 'open(path, "w")' in content and 'encoding="utf-8"' not in content:
            logger.info("Applying UTF-8 patch to dublib...")
            content = content.replace(
                'open(path, "w")',
                'open(path, "w", encoding="utf-8")'
            )
            dublib_path.write_text(content, encoding='utf-8')
            logger.info("UTF-8 patch applied successfully")

def log_task_message(task_id: str, level: str, message: str):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –ª–æ–≥–∏ –∑–∞–¥–∞—á–∏ (–æ—á–∏—â–∞–µ—Ç ANSI –∫–æ–¥—ã)"""
    if task_id not in task_logs:
        task_logs[task_id] = []
    
    # –û—á–∏—â–∞–µ–º ANSI escape –∫–æ–¥—ã –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è
    clean_message = strip_ansi_codes(message)
    
    log_entry = LogEntry(
        timestamp=datetime.now().isoformat(),
        level=level,
        message=clean_message,
        task_id=task_id
    )
    
    task_logs[task_id].append(log_entry)
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ–≥–æ–≤ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 1000)
    if len(task_logs[task_id]) > 1000:
        task_logs[task_id] = task_logs[task_id][-1000:]

def update_task_status(task_id: str, status: str, progress: int, message: str, result_data: Dict[str, Any] = None):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏"""
    if task_id in tasks_storage:
        tasks_storage[task_id].status = status
        tasks_storage[task_id].progress = progress
        tasks_storage[task_id].message = message
        tasks_storage[task_id].updated_at = datetime.now().isoformat()
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
        log_task_message(task_id, "INFO", f"Status: {status}, Progress: {progress}%, Message: {message}")
        
        if result_data:
            if hasattr(tasks_storage[task_id], 'results'):
                tasks_storage[task_id].results.append(result_data)
            elif hasattr(tasks_storage[task_id], 'current_slug'):
                tasks_storage[task_id].current_slug = result_data.get('filename', '')
        
        logger.info(f"Task {task_id}: {status} - {progress}% - {message}")
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ç—á –¥–ª—è UTF-8 –∫–æ–¥–∏—Ä–æ–≤–∫–∏"""
    dublib_path = get_melon_base_path() / "dublib" / "Methods" / "Filesystem.py"

    if dublib_path.exists():
        content = dublib_path.read_text(encoding='utf-8')
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ –ø–∞—Ç—á
        if 'open(path, "w")' in content and 'encoding="utf-8"' not in content:
            logger.info("Applying UTF-8 patch to dublib...")
            content = content.replace(
                'open(path, "w")',
                'open(path, "w", encoding="utf-8")'
            )
            dublib_path.write_text(content, encoding='utf-8')
            logger.info("UTF-8 patch applied successfully")

def ensure_cross_device_patch():
    """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –æ—à–∏–±–∫—É 'Invalid cross-device link' –≤ MangaBuilder"""
    builder_path = get_melon_base_path() / "Parsers" / "MangaBuilder.py"
    
    if builder_path.exists():
        content = builder_path.read_text(encoding='utf-8')
        # –ó–∞–º–µ–Ω—è–µ–º os.rename –Ω–∞ shutil.move –¥–ª—è cross-device –æ–ø–µ—Ä–∞—Ü–∏–π
        if "os.rename(" in content and "shutil.move(" not in content:
            logger.info("Applying cross-device patch to MangaBuilder...")
            content = content.replace("os.rename(", "shutil.move(")
            if "import shutil" not in content:
                content = "import shutil\n" + content
            builder_path.write_text(content, encoding='utf-8')
            logger.info("Cross-device patch applied successfully")

def send_progress_to_manga_service(task_id, status, progress, message=None, error=None, logs=None):
    try:
        payload = {
            "status": status,
            "progress": progress,
            "message": message,
            "error": error
        }
        if logs:
            payload["logs"] = logs if isinstance(logs, list) else [logs]
        url = f"http://manga-service:8081/api/parser/progress/{task_id}"
        resp = requests.post(url, json=payload, timeout=5)
        logger.info(f"Progress sent to MangaService: {payload}, response: {resp.status_code}")
    except Exception as e:
        logger.error(f"Failed to send progress to MangaService: {e}")

def update_task_status(task_id: str, status: str, progress: int, message: str, result: Optional[Dict] = None, error: Optional[str] = None):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ª–æ–≥–∏ –≤ MangaService"""
    if task_id in tasks_storage:
        tasks_storage[task_id].status = status
        tasks_storage[task_id].progress = progress
        tasks_storage[task_id].message = message
        tasks_storage[task_id].updated_at = datetime.now().isoformat()
        if result:
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–ø–∏—Å–æ–∫ results (–Ω–µ result!)
            if isinstance(result, list):
                tasks_storage[task_id].results.extend(result)
            else:
                tasks_storage[task_id].results.append(result)
        
        # –°–æ–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ª–æ–≥–∏ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å—Ç—Ä–æ–∫)
        logs_to_send = None
        if task_id in task_logs and len(task_logs[task_id]) > 0:
            recent_logs = task_logs[task_id][-10:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –ª–æ–≥–æ–≤
            logs_to_send = [f"[{log.timestamp}] [{log.level}] {log.message}" for log in recent_logs]
        
        send_progress_to_manga_service(task_id, status, progress, message, error, logs_to_send)

async def run_melon_command(command: List[str], task_id: str, timeout: int = 600) -> Dict[str, Any]:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∫–æ–º–∞–Ω–¥—É MelonService –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π timeout –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
    try:
        # –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –∫–æ–º–∞–Ω–¥—É
        base_path = get_melon_base_path()

        # –î–ª—è Windows –≤ Docker –∏—Å–ø–æ–ª—å–∑—É–µ–º python –Ω–∞–ø—Ä—è–º—É—é
        full_command = ["python", "main.py"] + command[2:]  # —É–±–∏—Ä–∞–µ–º "python main.py"

        logger.info(f"Running command: {' '.join(full_command)}")
        update_task_status(task_id, "RUNNING", 5, f"–ó–∞–ø—É—Å–∫ –∫–æ–º–∞–Ω–¥—ã: {' '.join(full_command)}")

        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å
        process = await asyncio.create_subprocess_exec(
            *full_command,
            cwd=base_path,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )

        # –ß–∏—Ç–∞–µ–º –≤—ã–≤–æ–¥ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
        stdout_lines = []
        stderr_lines = []
        last_update_time = datetime.now()
        
        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —á—Ç–µ–Ω–∏—è stdout
        async def read_stdout():
            nonlocal last_update_time
            if process.stdout:
                while True:
                    line = await process.stdout.readline()
                    if not line:
                        break
                    line_str = line.decode('utf-8', errors='ignore').strip()
                    if line_str:
                        stdout_lines.append(line_str)
                        log_task_message(task_id, "INFO", line_str)
                        last_update_time = datetime.now()
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã–≤–æ–¥–∞
                        if "Chapter" in line_str and "completed" in line_str:
                            update_task_status(task_id, "RUNNING", min(90, 10 + len(stdout_lines)), f"–ü–∞—Ä—Å–∏–Ω–≥: {line_str}")
                        elif "Parsing" in line_str and "..." in line_str:
                            update_task_status(task_id, "RUNNING", min(90, 10 + len(stdout_lines)), f"–ü–∞—Ä—Å–∏–Ω–≥: {line_str}")
                        elif "Building" in line_str:
                            update_task_status(task_id, "RUNNING", min(90, 10 + len(stdout_lines)), f"–ë–∏–ª–¥–∏–Ω–≥: {line_str}")
                        elif "Done in" in line_str:
                            update_task_status(task_id, "RUNNING", 95, f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ: {line_str}")

        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —á—Ç–µ–Ω–∏—è stderr
        async def read_stderr():
            nonlocal last_update_time
            if process.stderr:
                while True:
                    line = await process.stderr.readline()
                    if not line:
                        break
                    line_str = line.decode('utf-8', errors='ignore').strip()
                    if line_str:
                        stderr_lines.append(line_str)
                        log_task_message(task_id, "ERROR", line_str)
                        logger.warning(f"[{task_id}] STDERR: {line_str}")
                        last_update_time = datetime.now()

        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–≥–æ heartbeat (–∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥)
        async def heartbeat():
            nonlocal last_update_time
            while process.returncode is None:
                await asyncio.sleep(30)
                if process.returncode is None:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–Ω–æ–≤–∞ –ø–æ—Å–ª–µ sleep
                    elapsed = (datetime.now() - last_update_time).total_seconds()
                    log_task_message(task_id, "INFO", f"[Heartbeat] –ü—Ä–æ—Ü–µ—Å—Å –∞–∫—Ç–∏–≤–µ–Ω, –ø—Ä–æ—à–ª–æ {int(elapsed)}—Å —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è")
                    update_task_status(task_id, "RUNNING", min(90, 10 + len(stdout_lines)), f"–ü–∞—Ä—Å–∏–Ω–≥ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ... ({len(stdout_lines)} —Å—Ç—Ä–æ–∫ –ª–æ–≥–æ–≤)")

        # –ß–∏—Ç–∞–µ–º stdout, stderr –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º heartbeat
        await asyncio.gather(
            read_stdout(),
            read_stderr(),
            heartbeat()
        )

        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞
        return_code = await process.wait()

        stdout = '\n'.join(stdout_lines)
        stderr = '\n'.join(stderr_lines)

        if return_code == 0:
            logger.info(f"[{task_id}] Command completed successfully")
            update_task_status(task_id, "RUNNING", 95, "–ö–æ–º–∞–Ω–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            return {
                "success": True,
                "stdout": stdout,
                "stderr": stderr
            }
        else:
            logger.error(f"[{task_id}] Command failed with return code {return_code}")
            return {
                "success": False,
                "stdout": stdout,
                "stderr": stderr,
                "return_code": return_code
            }

    except Exception as e:
        logger.error(f"[{task_id}] Error running command: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }

async def execute_batch_parse_task(task_id: str, slugs: List[str], parser: str, auto_import: bool):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–∞–∫–µ—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å–ø–∏—Å–∫–∞ –º–∞–Ω–≥–∏ —Å –æ—Ç–¥–µ–ª—å–Ω—ã–º —ç—Ç–∞–ø–æ–º –∏–º–ø–æ—Ä—Ç–∞"""
    try:
        ensure_utf8_patch()
        ensure_cross_device_patch()
        
        total_slugs = len(slugs)
        results = []
        completed = 0
        failed = 0
        successfully_built = []  # –°–ø–∏—Å–æ–∫ —É—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –º–∞–Ω–≥ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –±–∏–ª–¥–∞ –¥–ª—è –∑–∞–¥–∞—á–∏
        build_states[task_id] = {"current_slug": None, "is_ready": False, "files_ready": False}
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞—á–∞–ª–∞
        tasks_storage[task_id].status = "running"
        tasks_storage[task_id].message = f"–ù–∞—á–∏–Ω–∞–µ–º –ø–∞–∫–µ—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∏ –±–∏–ª–¥ {total_slugs} –º–∞–Ω–≥–∏"
        tasks_storage[task_id].updated_at = datetime.now().isoformat()
        
        # –≠–¢–ê–ü 1: –ü–∞—Ä—Å–∏–Ω–≥ –∏ –±–∏–ª–¥ –≤—Å–µ—Ö –º–∞–Ω–≥
        logger.info(f"Starting batch parse and build phase for {total_slugs} manga")
        
        for i, slug in enumerate(slugs):
            try:
                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –Ω–æ–≤–æ–π –º–∞–Ω–≥–∏
                build_states[task_id].update({
                    "current_slug": slug,
                    "is_ready": False,
                    "files_ready": False
                })
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π —Å–ª–∞–≥
                tasks_storage[task_id].current_slug = slug
                tasks_storage[task_id].message = f"–ü–∞—Ä—Å–∏–Ω–≥: {slug} ({i+1}/{total_slugs})"
                tasks_storage[task_id].progress = int((i / total_slugs) * 35)  # 35% –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏ –±–∏–ª–¥–∞
                tasks_storage[task_id].updated_at = datetime.now().isoformat()
                
                logger.info(f"Batch parsing: processing {slug} ({i+1}/{total_slugs})")
                
                # –®–∞–≥ 1: –ü–∞—Ä—Å–∏–Ω–≥
                command = ["python", "main.py", "parse", slug, "--use", parser]
                result = await run_melon_command(command, task_id, timeout=1800)  # 30 –º–∏–Ω—É—Ç —Ç–∞–π–º–∞—É—Ç
                
                if not result["success"]:
                    failed += 1
                    results.append({
                        "slug": slug,
                        "status": "failed",
                        "step": "parse",
                        "error": result.get('stderr', 'Unknown parse error')
                    })
                    continue
                
                # –®–∞–≥ 2: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞
                tasks_storage[task_id].message = f"–ë–∏–ª–¥–∏–Ω–≥: {slug} ({i+1}/{total_slugs})"
                tasks_storage[task_id].updated_at = datetime.now().isoformat()
                
                build_command = ["python", "main.py", "build-manga", slug, "--use", parser, "-simple"]
                build_result = await run_melon_command(build_command, task_id, timeout=1800)  # 30 –º–∏–Ω—É—Ç —Ç–∞–π–º–∞—É—Ç
                
                if not build_result["success"]:
                    failed += 1
                    results.append({
                        "slug": slug,
                        "status": "failed",
                        "step": "build",
                        "error": build_result.get('stderr', 'Unknown build error')
                    })
                    continue
                
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ —É—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö
                successfully_built.append(slug)
                logger.info(f"Successfully built {slug}")
                
            except Exception as e:
                failed += 1
                results.append({
                    "slug": slug,
                    "status": "failed",
                    "step": "general",
                    "error": str(e)
                })
                logger.error(f"Error processing {slug}: {str(e)}")
        
        # –≠–¢–ê–ü 2: –ò–º–ø–æ—Ä—Ç –≤—Å–µ—Ö —É—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –º–∞–Ω–≥
        if auto_import and successfully_built:
            logger.info(f"Starting import phase for {len(successfully_built)} successfully built manga")
            
            # –î–∞–µ–º –≤—Ä–µ–º—è –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–æ–≤
            tasks_storage[task_id].message = f"–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–æ–≤..."
            tasks_storage[task_id].progress = 40
            tasks_storage[task_id].updated_at = datetime.now().isoformat()
            await asyncio.sleep(10)  # 10 —Å–µ–∫—É–Ω–¥ –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è I/O –æ–ø–µ—Ä–∞—Ü–∏–π
            
            for i, slug in enumerate(successfully_built):
                try:
                    tasks_storage[task_id].current_slug = slug
                    tasks_storage[task_id].message = f"–ò–º–ø–æ—Ä—Ç: {slug} ({i+1}/{len(successfully_built)})"
                    tasks_storage[task_id].progress = 40 + int((i / len(successfully_built)) * 55)  # 40-95% –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
                    tasks_storage[task_id].updated_at = datetime.now().isoformat()
                    
                    logger.info(f"Starting import for {slug}")
                    
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ –∏–º–ø–æ—Ä—Ç –≤ MangaService
                    import_url = "http://manga-service:8081/parser/import/" + slug
                    response = requests.post(import_url, timeout=180)  # 3 –º–∏–Ω—É—Ç—ã —Ç–∞–π–º–∞—É—Ç –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
                    
                    # –ù–∞–π–¥–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏ –æ–±–Ω–æ–≤–∏–º –µ–≥–æ
                    result_entry = None
                    for result in results:
                        if result.get("slug") == slug and result.get("status") == "completed":
                            result_entry = result
                            break
                    
                    if not result_entry:
                        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å –¥–ª—è —É—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω–Ω–æ–π –º–∞–Ω–≥–∏
                        result_entry = {
                            "slug": slug,
                            "status": "completed",
                            "manga_info": {},
                            "imported": True
                        }
                        results.append(result_entry)
                    
                    if response.status_code == 200:
                        import_data = response.json()
                        logger.info(f"Successfully imported {slug}")
                        result_entry["import_status"] = "success"
                        result_entry["manga_info"].update({
                            "title": import_data.get("title", ""),
                            "chapters": import_data.get("chapters", 0),
                            "import_result": import_data
                        })
                        completed += 1
                    else:
                        logger.warning(f"Failed to import {slug}: HTTP {response.status_code}")
                        result_entry["import_status"] = "failed"
                        result_entry["import_error"] = f"Import failed with HTTP {response.status_code}"
                        result_entry["import_response"] = response.text[:200] if response.text else "No response body"
                        
                except Exception as e:
                    logger.error(f"Failed to import {slug}: {str(e)}")
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ—à–∏–±–∫–æ–π –∏–º–ø–æ—Ä—Ç–∞
                    for result in results:
                        if result.get("slug") == slug:
                            result["import_status"] = "failed"
                            result["import_error"] = str(e)
                            break
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
        tasks_storage[task_id].message = f"–ü–∞–∫–µ—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –£—Å–ø–µ—à–Ω–æ: {completed}, –û—à–∏–±–æ–∫: {failed}"
        tasks_storage[task_id].progress = 100
        tasks_storage[task_id].status = "completed"
        tasks_storage[task_id].completed_slugs = completed
        tasks_storage[task_id].failed_slugs = failed
        tasks_storage[task_id].results = results
        tasks_storage[task_id].updated_at = datetime.now().isoformat()
        
        logger.info(f"Batch parsing completed. Successful: {completed}, Failed: {failed}")
        
        # –û—á–∏—â–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –±–∏–ª–¥–∞
        if task_id in build_states:
            del build_states[task_id]

    except Exception as e:
        update_task_status(task_id, "FAILED", 100, f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        logger.error(f"Critical error in batch parsing: {str(e)}")

# –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã

@app.get("/tasks")
async def get_all_tasks():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –∑–∞–¥–∞—á"""
    tasks = []
    for task_id, task in tasks_storage.items():
        task_dict = {
            "task_id": task.task_id,
            "status": task.status,
            "progress": task.progress,
            "message": task.message,
            "created_at": task.created_at,
            "updated_at": task.updated_at,
            "total_slugs": getattr(task, 'total_slugs', 1),
            "completed_slugs": getattr(task, 'completed_slugs', 0),
            "failed_slugs": getattr(task, 'failed_slugs', 0),
            "current_slug": getattr(task, 'current_slug', None),
        }
        tasks.append(task_dict)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ —Å–≤–µ—Ä—Ö—É)
    tasks.sort(key=lambda x: x['created_at'], reverse=True)
    return tasks

@app.post("/tasks/clear-completed")
async def clear_completed_tasks():
    """–û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –∏ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –∑–∞–¥–∞—á"""
    completed_tasks = []
    for task_id, task in list(tasks_storage.items()):
        if task.status in ["completed", "failed"]:
            completed_tasks.append(task_id)
            del tasks_storage[task_id]
            if task_id in task_logs:
                del task_logs[task_id]
            if task_id in build_states:
                del build_states[task_id]
    
    return {"cleared": len(completed_tasks), "task_ids": completed_tasks}

@app.get("/")
async def get_main():
    return {"message": "MelonService API Server", "status": "running", "monitor": "/monitor.html"}

@app.post("/parse")
async def parse_manga(request: ParseRequest, background_tasks: BackgroundTasks):
    """–ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–π –º–∞–Ω–≥–∏"""
    task_id = str(uuid.uuid4())
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
    task = ParseStatus(
        task_id=task_id,
        status="pending",
        progress=0,
        message=f"–ü–∞—Ä—Å–∏–Ω–≥ –º–∞–Ω–≥–∏ {request.slug}",
        created_at=datetime.now().isoformat(),
        updated_at=datetime.now().isoformat(),
        total_slugs=1,
        completed_slugs=0,
        failed_slugs=0
    )
    
    tasks_storage[task_id] = task
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á—É —á–µ—Ä–µ–∑ BackgroundTasks
    background_tasks.add_task(execute_parse_task, task_id, request.slug, request.parser)
    
    return {"task_id": task_id, "status": "pending"}

@app.post("/build")
async def build_manga(request: BuildRequest, background_tasks: BackgroundTasks):
    """–ë–∏–ª–¥ –æ–¥–Ω–æ–π –º–∞–Ω–≥–∏"""
    task_id = str(uuid.uuid4())
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
    task = ParseStatus(
        task_id=task_id,
        status="pending",
        progress=0,
        message=f"–ë–∏–ª–¥ –º–∞–Ω–≥–∏ {request.slug}",
        created_at=datetime.now().isoformat(),
        updated_at=datetime.now().isoformat(),
        total_slugs=1,
        completed_slugs=0,
        failed_slugs=0
    )
    
    tasks_storage[task_id] = task
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á—É —á–µ—Ä–µ–∑ BackgroundTasks
    background_tasks.add_task(execute_build_task, task_id, request.slug, request.parser, None, request.type)
    
    return {"task_id": task_id, "status": "pending"}

@app.post("/batch-start")
async def start_batch_parse(request: BatchParseRequest):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–∞–∫–µ—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å–ø–∏—Å–∫–∞ –º–∞–Ω–≥–∏"""
    task_id = str(uuid.uuid4())
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
    task = BatchParseStatus(
        task_id=task_id,
        status="pending",
        progress=0,
        message=f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –ø–∞–∫–µ—Ç–Ω–æ–º—É –ø–∞—Ä—Å–∏–Ω–≥—É {len(request.slugs)} –º–∞–Ω–≥–∏",
        created_at=datetime.now().isoformat(),
        updated_at=datetime.now().isoformat(),
        total_slugs=len(request.slugs),
        completed_slugs=0,
        failed_slugs=0
    )
    
    tasks_storage[task_id] = task
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á—É –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
    asyncio.create_task(execute_batch_parse_task(task_id, request.slugs, request.parser, request.auto_import))
    
    return {"task_id": task_id, "status": "started"}

@app.post("/batch-parse")
async def batch_parse_alias(request: BatchParseRequest):
    """–ê–ª–∏–∞—Å –¥–ª—è batch-start - –∑–∞–ø—É—Å–∫–∞–µ—Ç –ø–∞–∫–µ—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å–ø–∏—Å–∫–∞ –º–∞–Ω–≥–∏"""
    return await start_batch_parse(request)

@app.get("/logs/{task_id}")
async def get_task_logs(task_id: str, limit: int = 100):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–≥–æ–≤ –∑–∞–¥–∞—á–∏"""
    if task_id not in task_logs:
        raise HTTPException(status_code=404, detail="Task logs not found")
    
    logs = task_logs[task_id]
    if limit > 0:
        logs = logs[-limit:]
    
    return {"task_id": task_id, "logs": [log.dict() for log in logs]}

@app.get("/logs/{task_id}/stream")
async def stream_task_logs(task_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–≥–æ–≤ –∑–∞–¥–∞—á–∏ –≤ —Ä–µ–∂–∏–º–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ (SSE)"""
    if task_id not in task_logs:
        raise HTTPException(status_code=404, detail="Task not found")
    
    async def generate():
        last_log_index = 0
        while True:
            if task_id in task_logs and len(task_logs[task_id]) > last_log_index:
                new_logs = task_logs[task_id][last_log_index:]
                for log_entry in new_logs:
                    yield f"data: {log_entry.json()}\n\n"
                last_log_index = len(task_logs[task_id])
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –ª–∏ –∑–∞–¥–∞—á–∞
            if task_id in tasks_storage and tasks_storage[task_id].status in ["completed", "failed"]:
                break
                
            await asyncio.sleep(1)
    
    return StreamingResponse(generate(), media_type="text/event-stream")

@app.get("/status/{task_id}")
async def get_task_status(task_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏"""
    if task_id not in tasks_storage:
        raise HTTPException(status_code=404, detail="Task not found")
    
    task = tasks_storage[task_id]
    result = {
        "task_id": task.task_id,
        "status": task.status,
        "progress": task.progress,
        "message": task.message,
        "created_at": task.created_at,
        "updated_at": task.updated_at,
        "total_slugs": task.total_slugs,
        "completed_slugs": task.completed_slugs,
        "failed_slugs": task.failed_slugs,
        "current_slug": task.current_slug,
        "results": task.results
    }
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –±–∏–ª–¥–∞, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
    if task_id in build_states:
        result["build_state"] = build_states[task_id]
    
    return result

async def execute_parse_task(task_id: str, slug: str, parser: str):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–¥–∞—á—É –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ–¥–Ω–æ–π –º–∞–Ω–≥–∏"""
    try:
        ensure_utf8_patch()
        ensure_cross_device_patch()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞—á–∞–ª–∞
        update_task_status(task_id, "IMPORTING_MANGA", 5, "–ü—Ä–∏–º–µ–Ω–µ–Ω—ã –ø–∞—Ç—á–∏")
        
        command = ["python", "main.py", "parse", slug, "--use", parser]
        result = await run_melon_command(command, task_id, timeout=1800)
        
        if result["success"]:
            update_task_status(task_id, "IMPORTING_MANGA", 80, "–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç...")
            
            # –í–ê–ñ–ù–û: –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º slug –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ JSON —Ñ–∞–π–ª–∞
            # MelonService —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∞–π–ª—ã –ë–ï–ó ID: "sweet-home-kim-carnby-.json"
            # –ù–æ slug –º–æ–∂–µ—Ç –ø—Ä–∏–π—Ç–∏ —Å ID: "3754--sweet-home-kim-carnby-"
            normalized_slug = slug
            if "--" in slug:
                parts = slug.split("--", 1)
                if len(parts) == 2 and parts[0].isdigit():
                    normalized_slug = parts[1]
                    logger.info(f"üîß –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è slug –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ JSON: '{slug}' ‚Üí '{normalized_slug}'")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–∑–¥–∞–ª—Å—è –ª–∏ JSON —Ñ–∞–π–ª (—Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º slug)
            json_path = get_melon_base_path() / "Output" / parser / "titles" / f"{normalized_slug}.json"
            logger.info(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ JSON —Ñ–∞–π–ª–∞: {json_path}")
            
            if json_path.exists():
                logger.info(f"‚úÖ JSON —Ñ–∞–π–ª –Ω–∞–π–¥–µ–Ω: {json_path}")
                # –ß–∏—Ç–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–∞–Ω–≥–µ
                with open(json_path, 'r', encoding='utf-8') as f:
                    manga_data = json.load(f)

                update_task_status(
                    task_id,
                    "COMPLETED",
                    100,
                    "–ü–∞—Ä—Å–∏–Ω–≥ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω",
                    {
                        "filename": normalized_slug,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π slug
                        "title": manga_data.get("localized_name") or manga_data.get("eng_name") or manga_data.get("title", ""),
                        "chapters": sum(len(chapters) for chapters in manga_data.get("content", {}).values()),
                        "branches": len(manga_data.get("content", {}))
                    }
                )
                
                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ–º build –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ (—Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º slug)
                asyncio.create_task(execute_build_task(task_id, normalized_slug, parser, None, "simple"))
            else:
                logger.error(f"‚ùå JSON —Ñ–∞–π–ª –ù–ï –Ω–∞–π–¥–µ–Ω: {json_path}")
                # –õ–æ–≥–∏—Ä—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                titles_dir = get_melon_base_path() / "Output" / parser / "titles"
                if titles_dir.exists():
                    available_files = [f.stem for f in titles_dir.glob("*.json")]
                    logger.error(f"üìÇ –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∞–π–ª—ã: {available_files}")
                update_task_status(task_id, "FAILED", 100, "–ü–∞—Ä—Å–∏–Ω–≥ –≤—ã–ø–æ–ª–Ω–µ–Ω, –Ω–æ JSON —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        else:
            update_task_status(
                task_id,
                "FAILED",
                100,
                f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {result.get('stderr', 'Unknown error')}"
            )

    except Exception as e:
        update_task_status(task_id, "FAILED", 100, f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")

async def execute_build_task(task_id: str, slug: str, parser: str, target_language: str = None, build_type: str = "simple"):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–¥–∞—á—É –±–∏–ª–¥–∞ –æ–¥–Ω–æ–π –º–∞–Ω–≥–∏"""
    try:
        update_task_status(task_id, "IMPORTING_MANGA", 10, "–ù–∞—á–∏–Ω–∞–µ–º –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞...")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—á –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º build –∫–æ–º–∞–Ω–¥—ã
        ensure_cross_device_patch()
        
        # –í–ê–ñ–ù–û: –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º slug (—É–±–∏—Ä–∞–µ–º ID, –µ—Å–ª–∏ –µ—Å—Ç—å)
        # MelonService —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∞–π–ª—ã –ë–ï–ó ID: "sweet-home-kim-carnby-.json"
        # –ù–æ MangaService –º–æ–∂–µ—Ç –ø–µ—Ä–µ–¥–∞—Ç—å slug —Å ID: "3754--sweet-home-kim-carnby-"
        normalized_slug = slug
        if "--" in slug:
            parts = slug.split("--", 1)
            if len(parts) == 2 and parts[0].isdigit():
                normalized_slug = parts[1]
                logger.info(f"üîß –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è slug –¥–ª—è –±–∏–ª–¥–∞: '{slug}' ‚Üí '{normalized_slug}'")
        
        # –ö–æ–º–∞–Ω–¥–∞ –±–∏–ª–¥–∞ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º slug
        command = ["python", "main.py", "build-manga", normalized_slug, "--use", parser]
        
        if build_type == "simple":
            command.append("-simple")
        elif build_type == "zip":
            command.append("-zip")
        elif build_type == "cbz":
            command.append("-cbz")
        
        result = await run_melon_command(command, task_id, timeout=1800)
        
        if result["success"]:
            update_task_status(
                task_id,
                "COMPLETED",
                100,
                f"–ê—Ä—Ö–∏–≤ —É—Å–ø–µ—à–Ω–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω ({build_type})",
                {
                    "filename": slug,
                    "archive_type": build_type
                }
            )
        else:
            error_msg = f"–û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è: {result.get('stderr', 'Unknown error')}"
            logger.error(f"Build command failed for {slug}: stdout={result.get('stdout', '')}, stderr={result.get('stderr', '')}, return_code={result.get('return_code', 'unknown')}")
            
            update_task_status(
                task_id,
                "FAILED",
                100,
                error_msg
            )

    except Exception as e:
        logger.error(f"Critical error in build task {task_id}: {str(e)}")
        update_task_status(task_id, "FAILED", 100, f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")

@app.get("/list-parsed")
async def list_parsed_manga():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö –º–∞–Ω–≥"""
    try:
        output_path = get_melon_base_path() / "Output"
        parsed_manga = []
        
        for parser_dir in output_path.iterdir():
            if parser_dir.is_dir():
                titles_dir = parser_dir / "titles"
                if titles_dir.exists():
                    for json_file in titles_dir.glob("*.json"):
                        try:
                            with open(json_file, 'r', encoding='utf-8') as f:
                                manga_data = json.load(f)
                                # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –ø–æ–ª–µ–π
                                title = (manga_data.get("title") or 
                                        manga_data.get("localized_name") or 
                                        manga_data.get("eng_name") or 
                                        manga_data.get("slug", "Unknown"))
                                
                                parsed_manga.append({
                                    "slug": json_file.stem,
                                    "title": title,
                                    "parser": parser_dir.name,
                                    "chapters": sum(len(chapters) for chapters in manga_data.get("content", {}).values()),
                                    "branches": len(manga_data.get("content", {}))
                                })
                        except Exception as e:
                            logger.warning(f"Error reading {json_file}: {str(e)}")
        
        return {"manga_list": parsed_manga}
    
    except Exception as e:
        logger.error(f"Error listing parsed manga: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/delete/{filename}")
async def delete_manga(filename: str):
    """–£–¥–∞–ª–µ–Ω–∏–µ –º–∞–Ω–≥–∏"""
    try:
        output_path = get_melon_base_path() / "Output"
        deleted_items = []
        
        for parser_dir in output_path.iterdir():
            if parser_dir.is_dir():
                # –£–¥–∞–ª—è–µ–º JSON —Ñ–∞–π–ª
                json_file = parser_dir / "titles" / f"{filename}.json"
                if json_file.exists():
                    json_file.unlink()
                    deleted_items.append(f"JSON —Ñ–∞–π–ª: {json_file.name}")
                
                # –£–¥–∞–ª—è–µ–º –ø–∞–ø–∫—É —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
                images_dir = parser_dir / "archives" / filename
                if images_dir.exists():
                    shutil.rmtree(images_dir)
                    deleted_items.append(f"–ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏: {filename}")
        
        if deleted_items:
            logger.info(f"Deleted manga '{filename}': {', '.join(deleted_items)}")
            return {
                "success": True,
                "message": f"–ú–∞–Ω–≥–∞ '{filename}' —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–∞",
                "deleted_items": deleted_items
            }
        else:
            return {
                "success": False,
                "message": f"–ú–∞–Ω–≥–∞ '{filename}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
            }
    
    except Exception as e:
        error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –º–∞–Ω–≥–∏ '{filename}': {str(e)}"
        logger.error(error_msg)
        return {"success": False, "message": error_msg}

@app.get("/manga-info/{filename}")
async def get_manga_info(filename: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–∞–Ω–≥–µ"""
    try:
        output_path = get_melon_base_path() / "Output"
        logger.info(f"üîç –ü–æ–∏—Å–∫ manga-info –¥–ª—è filename='{filename}'")
        logger.info(f"üìÇ Output path: {output_path}")
        
        for parser_dir in output_path.iterdir():
            if parser_dir.is_dir():
                json_file = parser_dir / "titles" / f"{filename}.json"
                logger.info(f"üîé –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª: {json_file} (exists={json_file.exists()})")
                
                if json_file.exists():
                    logger.info(f"‚úÖ –§–∞–π–ª –Ω–∞–π–¥–µ–Ω: {json_file}")
                    with open(json_file, 'r', encoding='utf-8') as f:
                        return json.load(f)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        all_files = []
        for parser_dir in output_path.iterdir():
            if parser_dir.is_dir():
                titles_dir = parser_dir / "titles"
                if titles_dir.exists():
                    all_files.extend([f.stem for f in titles_dir.glob("*.json")])
        
        logger.error(f"‚ùå –§–∞–π–ª '{filename}.json' –Ω–µ –Ω–∞–π–¥–µ–Ω. –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∞–π–ª—ã: {all_files}")
        raise HTTPException(status_code=404, detail=f"–ú–∞–Ω–≥–∞ '{filename}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {all_files}")
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting manga info for {filename}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/catalog/{page}")
async def get_catalog(page: int, parser: str = "mangalib", limit: int = 60):
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ slug'–æ–≤ –º–∞–Ω–≥ –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞ MangaLib –ø–æ –Ω–æ–º–µ—Ä—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã.
    
    Args:
        page: –ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞—Ç–∞–ª–æ–≥–∞ (–Ω–∞—á–∏–Ω–∞—è —Å 1)
        parser: –ü–∞—Ä—Å–µ—Ä (mangalib, slashlib, hentailib)
        limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∞–Ω–≥ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 60)
    
    Returns:
        JSON —Å–æ —Å–ø–∏—Å–∫–æ–º slug'–æ–≤ –º–∞–Ω–≥
    """
    try:
        logger.info(f"Fetching catalog page {page} for {parser}, limit: {limit}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º Site-Id
        site_ids = {
            "mangalib": "1",
            "slashlib": "2", 
            "hentailib": "4"
        }
        site_id = site_ids.get(parser, "1")
        
        # –ó–∞–ø—Ä–æ—Å –∫ MangaLib API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞
        # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∫–∞–∫ –≤ –ø–∞—Ä—Å–µ—Ä–µ: fields[]=value&fields[]=value2
        api_url = f"https://api.cdnlibs.org/api/manga?fields[]=rate_avg&fields[]=rate&fields[]=releaseDate&page={page}"
        
        # –ò–º–∏—Ç–∏—Ä—É–µ–º –Ω–∞—Å—Ç–æ—è—â–∏–π –±—Ä–∞—É–∑–µ—Ä —Å –ø–æ–ª–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        headers = {
            "Site-Id": site_id,
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Origin": f"https://{parser}.me",
            "Referer": f"https://{parser}.me/manga-list",
            "Sec-Fetch-Dest": "empty",
            "Sec-Fetch-Mode": "cors",
            "Sec-Fetch-Site": "cross-site",
            "Sec-Ch-Ua": '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"',
            "Sec-Ch-Ua-Mobile": "?0",
            "Sec-Ch-Ua-Platform": '"Windows"'
        }
        
        # –ó–∞–ø—Ä–æ—Å –±–µ–∑ params, –≤—Å—ë –≤ URL (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–æ—Ç–∞—Ü–∏—é –ø—Ä–æ–∫—Å–∏)
        current_proxy = get_proxy_for_request()
        response = requests.get(api_url, headers=headers, proxies=current_proxy, timeout=30)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        logger.debug(f"Request URL: {response.url}")
        
        response.raise_for_status()
        
        data = response.json()
        logger.debug(f"API Response keys: {data.keys() if isinstance(data, dict) else 'not a dict'}")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–∞–Ω–≥
        manga_list = data.get("data", [])
        if not manga_list and isinstance(data, list):
            manga_list = data
        
        meta = data.get("meta", {})
        total = meta.get("total", meta.get("total_results", 0))
        per_page = meta.get("per_page", len(manga_list))
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ slug'–æ–≤
        slugs = []
        for manga in manga_list[:limit]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ limit —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            # MangaLib –∏–∑–º–µ–Ω–∏–ª —Å—Ç—Ä—É–∫—Ç—É—Ä—É URL: —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è slug_url (—Ñ–æ—Ä–º–∞—Ç: ID--slug)
            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: slug_url > slug > eng_name
            slug = manga.get("slug_url", manga.get("slug", manga.get("eng_name", "")))
            if slug:
                slugs.append(slug)
        
        logger.info(f"Successfully fetched {len(slugs)} manga slugs from page {page} (total in response: {len(manga_list)})")
        
        return {
            "success": True,
            "page": page,
            "parser": parser,
            "limit": limit,
            "per_page": per_page,
            "total": total,
            "count": len(slugs),
            "slugs": slugs
        }
        
    except requests.exceptions.Timeout:
        error_msg = f"Timeout fetching catalog page {page}"
        logger.error(error_msg)
        return {"success": False, "error": error_msg}
    except requests.exceptions.RequestException as e:
        error_msg = f"Request error fetching catalog: {str(e)}"
        logger.error(error_msg)
        return {"success": False, "error": error_msg}
    except Exception as e:
        error_msg = f"Error fetching catalog page {page}: {str(e)}"
        logger.error(error_msg)
        return {"success": False, "error": error_msg}

@app.get("/manga-info/{slug}/chapters-only")
async def get_chapters_metadata_only_endpoint(slug: str, parser: str = "mangalib"):
    try:
        site_ids = {
            "mangalib": "1",
            "slashlib": "2", 
            "hentailib": "4"
        }
        site_id = site_ids.get(parser, "1")
        
        # –ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –∫ MangaLib API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –≥–ª–∞–≤
        api_url = f"https://api.cdnlibs.org/api/manga/{slug}/chapters"
        
        # –ò–º–∏—Ç–∏—Ä—É–µ–º –Ω–∞—Å—Ç–æ—è—â–∏–π –±—Ä–∞—É–∑–µ—Ä
        headers = {
            "Site-Id": site_id,
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Origin": f"https://{parser}.me",
            "Referer": f"https://{parser}.me/{slug}",
            "Sec-Fetch-Dest": "empty",
            "Sec-Fetch-Mode": "cors",
            "Sec-Fetch-Site": "cross-site",
            "Sec-Ch-Ua": '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"',
            "Sec-Ch-Ua-Mobile": "?0",
            "Sec-Ch-Ua-Platform": '"Windows"'
        }
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–æ—Ç–∞—Ü–∏—é –ø—Ä–æ–∫—Å–∏
        current_proxy = get_proxy_for_request()
        response = requests.get(api_url, headers=headers, proxies=current_proxy, timeout=30)
        
        if response.status_code == 200:
            data = response.json().get("data", [])
            
            chapters = []
            for chapter_data in data:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –≤–µ—Ç–∫–∏ –≥–ª–∞–≤—ã
                for branch_data in chapter_data.get("branches", []):
                    chapters.append({
                        "volume": chapter_data.get("volume"),
                        "number": chapter_data.get("number"),
                        "name": chapter_data.get("name", ""),
                        "id": branch_data.get("id"),
                        "branch_id": branch_data.get("branch_id")
                    })
            
            logger.info(f"Successfully retrieved {len(chapters)} chapters metadata for slug: {slug}")
            
            return {
                "success": True,
                "slug": slug,
                "parser": parser,
                "total_chapters": len(chapters),
                "chapters": chapters
            }
        else:
            error_msg = f"MangaLib API returned status {response.status_code}"
            logger.error(f"Error getting chapters metadata: {error_msg}")
            return {
                "success": False,
                "error": error_msg,
                "status_code": response.status_code
            }
            
    except requests.Timeout:
        error_msg = "Request to MangaLib API timed out"
        logger.error(error_msg)
        return {
            "success": False,
            "error": error_msg
        }
    except Exception as e:
        error_msg = f"Error getting chapters metadata: {str(e)}"
        logger.error(error_msg)
        return {
            "success": False,
            "error": error_msg
        }

@app.get("/images/{filename}/{chapter}/{page}")
async def get_image(filename: str, chapter: str, page: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    try:
        output_path = get_melon_base_path() / "Output"
        
        for parser_dir in output_path.iterdir():
            if parser_dir.is_dir():
                manga_dir = parser_dir / "archives" / filename
                if manga_dir.exists():
                    # –ò—â–µ–º –ø–∞–ø–∫—É –≥–ª–∞–≤—ã, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –Ω–æ–º–µ—Ä–∞ –≥–ª–∞–≤—ã
                    chapter_dir = None
                    for potential_dir in manga_dir.iterdir():
                        if potential_dir.is_dir():
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–Ω–∞—á–∞–ª–∞
                            if potential_dir.name == chapter:
                                chapter_dir = potential_dir
                                break
                            # –ü–æ—Ç–æ–º –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ —Å –Ω–æ–º–µ—Ä–∞ –≥–ª–∞–≤—ã
                            elif potential_dir.name.startswith(f"{chapter}.") or potential_dir.name.startswith(f"{chapter} "):
                                chapter_dir = potential_dir
                                break
                    
                    if chapter_dir:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –ø–∞–ø–∫–µ –≥–ª–∞–≤—ã
                        for ext in ['.png', '.jpg', '.jpeg', '.webp']:
                            image_path = chapter_dir / f"{page}{ext}"
                            if image_path.exists():
                                return FileResponse(
                                    path=str(image_path),
                                    media_type=f"image/{ext[1:]}",
                                    headers={
                                        "Cache-Control": "public, max-age=3600",
                                        "Access-Control-Allow-Origin": "*"
                                    }
                                )
                
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ archives, –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤ images
                manga_dir = parser_dir / "images" / filename
                if manga_dir.exists():
                    # –ò—â–µ–º –ø–∞–ø–∫—É –≥–ª–∞–≤—ã, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –Ω–æ–º–µ—Ä–∞ –≥–ª–∞–≤—ã
                    chapter_dir = None
                    for potential_dir in manga_dir.iterdir():
                        if potential_dir.is_dir():
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–Ω–∞—á–∞–ª–∞
                            if potential_dir.name == chapter:
                                chapter_dir = potential_dir
                                break
                            # –ü–æ—Ç–æ–º –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ —Å –Ω–æ–º–µ—Ä–∞ –≥–ª–∞–≤—ã
                            elif potential_dir.name.startswith(f"{chapter}.") or potential_dir.name.startswith(f"{chapter} "):
                                chapter_dir = potential_dir
                                break
                    
                    if chapter_dir:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –ø–∞–ø–∫–µ –≥–ª–∞–≤—ã
                        for ext in ['.png', '.jpg', '.jpeg', '.webp']:
                            image_path = chapter_dir / f"{page}{ext}"
                            if image_path.exists():
                                return FileResponse(
                                    path=str(image_path),
                                    media_type=f"image/{ext[1:]}",
                                    headers={
                                        "Cache-Control": "public, max-age=3600",
                                        "Access-Control-Allow-Origin": "*"
                                    }
                                )
        
        raise HTTPException(status_code=404, detail=f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {filename}/{chapter}/{page}")
    
    except Exception as e:
        logger.error(f"Error serving image {filename}/{chapter}/{page}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/cover/{filename}")
async def get_cover(filename: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±–ª–æ–∂–∫–∏ –º–∞–Ω–≥–∏"""
    try:
        output_path = get_melon_base_path() / "Output"
        
        for parser_dir in output_path.iterdir():
            if parser_dir.is_dir():
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—É—Ç–∏ –∫ –æ–±–ª–æ–∂–∫–µ
                possible_paths = [
                    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—É—Ç–∏ (–¥–ª—è —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞)
                    parser_dir / "archives" / filename / "cover.jpg",
                    parser_dir / "archives" / filename / "cover.png",
                    parser_dir / "archives" / filename / "cover.webp",
                    parser_dir / "images" / filename / "cover.jpg",
                    parser_dir / "images" / filename / "cover.png",
                    parser_dir / "images" / filename / "cover.webp",
                ]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—É—Ç–∏
                for cover_path in possible_paths:
                    if cover_path.exists():
                        return FileResponse(
                            path=str(cover_path),
                            media_type=f"image/{cover_path.suffix[1:]}",
                            headers={
                                "Cache-Control": "public, max-age=86400",  # –ö—ç—à –Ω–∞ —Å—É—Ç–∫–∏
                                "Access-Control-Allow-Origin": "*"
                            }
                        )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–ø–∫—É covers —Å UUID —Ñ–∞–π–ª–∞–º–∏
                covers_dir = parser_dir / "images" / filename / "covers"
                if covers_dir.exists():
                    # –ò—â–µ–º –ø–µ—Ä–≤—ã–π —Ñ–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ covers
                    for cover_file in covers_dir.glob("*"):
                        if cover_file.is_file() and cover_file.suffix.lower() in ['.jpg', '.jpeg', '.png', '.webp']:
                            return FileResponse(
                                path=str(cover_file),
                                media_type=f"image/{cover_file.suffix[1:]}",
                                headers={
                                    "Cache-Control": "public, max-age=86400",  # –ö—ç—à –Ω–∞ —Å—É—Ç–∫–∏
                                    "Access-Control-Allow-Origin": "*"
                                }
                            )
        
        raise HTTPException(status_code=404, detail=f"–û–±–ª–æ–∂–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –¥–ª—è –º–∞–Ω–≥–∏: {filename}")
    
    except Exception as e:
        logger.error(f"Error serving cover for {filename}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8084)