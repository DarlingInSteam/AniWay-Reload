"""
–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –ø–æ—Ç–æ–∫–∞–º–∏.
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è –ø–æ–¥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏.
"""

from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock, Semaphore
from time import sleep, time
from typing import List, Dict, Callable, Optional, Any
import logging
try:
    import requests
except Exception:
    requests = None

logger = logging.getLogger(__name__)


class AdaptiveParallelDownloader:
    """
    –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.

    –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–∫—Å–∏
    - Thread-safe –æ–ø–µ—Ä–∞—Ü–∏–∏
    - –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ —Å retry
    - –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π throttling –ø—Ä–∏ rate limiting (429)
    - –î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å
    """

    def __init__(
        self,
        proxy_count: int,
        download_func: Callable[..., Optional[str]],
        max_workers_per_proxy: int = 1,
        max_retries: int = 3,
        base_delay: float = 0.1,
        retry_delay: float = 1.0,
        max_total_workers: Optional[int] = None,
        proxy_pool: Optional[list] = None,
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑—á–∏–∫–∞.

        :param proxy_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏
        :param download_func: –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ø—Ä–∏–Ω–∏–º–∞–µ—Ç URL, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç filename –∏–ª–∏ None)
        :param max_workers_per_proxy: –ú–∞–∫—Å–∏–º—É–º –ø–æ—Ç–æ–∫–æ–≤ –Ω–∞ –æ–¥–∏–Ω –ø—Ä–æ–∫—Å–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 2)
        :param max_retries: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        :param base_delay: –ë–∞–∑–æ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (—Å–µ–∫)
        :param retry_delay: –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º –ø—Ä–∏ –æ—à–∏–±–∫–µ (—Å–µ–∫)
        :param max_total_workers: –ñ–µ—Å—Ç–∫–∏–π –ø—Ä–µ–¥–µ–ª –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∞–≤—Ç–æ—Ä–∞—Å—á–µ—Ç)
        """
        # –°—á–∏—Ç–∞–µ–º —Ä–∞–∑—É–º–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ worker-–æ–≤: proxy_count * workers_per_proxy
        computed_workers = max(1, proxy_count * max_workers_per_proxy)

        # Allow using more workers when proxy_count is large; keep a safe minimum cap of 16
        # Use max_workers_per_proxy to compute a reasonable cap (e.g., 2 workers per proxy)
        cap = max(16, proxy_count * max_workers_per_proxy)
        computed_workers = min(computed_workers, cap)

        if proxy_count == 1:
            computed_workers = min(computed_workers, max(2, max_workers_per_proxy + 1))
        elif proxy_count == 2:
            computed_workers = min(computed_workers, 4)
        elif proxy_count == 3:
            computed_workers = min(computed_workers, 6)
        elif proxy_count <= 5:
            computed_workers = min(computed_workers, 8)

        if max_total_workers is not None:
            try:
                override_value = int(max_total_workers)
                if override_value > 0:
                    computed_workers = max(1, min(override_value, 32))
            except (TypeError, ValueError):
                logger.warning(f"‚ö†Ô∏è Invalid max_total_workers override: {max_total_workers}")

        self.max_workers = computed_workers

        self.download_func = download_func
        self.max_retries = max_retries
        self.base_delay = base_delay
        self.retry_delay = retry_delay
        # Optional deterministic proxy pool (list of {'http':..., 'https':...})
        self.proxy_pool = proxy_pool or []

        # Per-proxy concurrency control and session reuse to improve connection pooling
        self._proxy_semaphores: Dict[int, Semaphore] = {}
        self._proxy_sessions: Dict[int, "requests.Session"] = {}
        if self.proxy_pool:
            for i, p in enumerate(self.proxy_pool):
                # limit concurrent connections per proxy to max_workers_per_proxy
                self._proxy_semaphores[i] = Semaphore(max_workers_per_proxy)
                # create a session per proxy to reuse TCP connections (only if requests is available)
                if requests is not None:
                    try:
                        s = requests.Session()
                        # set the proxy on the session so underlying poolmanager will use it
                        if isinstance(p, dict):
                            s.proxies.update(p)
                        # increase pool connections a bit
                        try:
                            adapter = requests.adapters.HTTPAdapter(pool_connections=max_workers_per_proxy + 2,
                                                                    pool_maxsize=max_workers_per_proxy + 10)
                            s.mount('http://', adapter)
                            s.mount('https://', adapter)
                        except Exception:
                            pass
                        self._proxy_sessions[i] = s
                    except Exception:
                        # fall back to no session for this proxy
                        self._proxy_sessions[i] = None
                else:
                    self._proxy_sessions[i] = None

        # Thread-safe —Å—á—ë—Ç—á–∏–∫–∏
        self._lock = Lock()
        self._downloaded = 0
        self._failed = 0
        self._total = 0

        # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π throttling
        self._rate_limit_detected = False
        self._current_delay = base_delay
        self._last_429_time = 0

        # –ï–¥–∏–Ω–æ—Ä–∞–∑–æ–≤—ã–π –ª–æ–≥ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–æ—Ä–∫–µ—Ä–æ–≤ (–≤—Å–µ–≥–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º)
        override_note = f", override={max_total_workers}" if max_total_workers else ""
        pool_note = f", proxy_pool={len(self.proxy_pool)}" if self.proxy_pool else ""
        logger.info(
            f"‚öôÔ∏è Workers: {self.max_workers} active, {proxy_count} proxies, {base_delay}s delay{override_note}{pool_note}"
        )

    def _adaptive_delay(self):
        """–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ —Å —É—á—ë—Ç–æ–º rate limiting."""
        current_time = time()

        # –ï—Å–ª–∏ –Ω–µ–¥–∞–≤–Ω–æ –±—ã–ª 429 (–≤ —Ç–µ—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 30 —Å–µ–∫—É–Ω–¥)
        if self._rate_limit_detected and (current_time - self._last_429_time) < 30:
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –≤ 3 —Ä–∞–∑–∞
            delay = self._current_delay * 3
            logger.warning(f"‚ö†Ô∏è Rate limit active, increased delay to {delay}s")
        else:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –±–∞–∑–æ–≤–æ–π –∑–∞–¥–µ—Ä–∂–∫–µ
            delay = self.base_delay
            if self._rate_limit_detected:
                self._rate_limit_detected = False
                logger.info(f"‚úÖ Rate limit cooldown ended, delay back to {delay}s")

        sleep(delay)

    def _handle_rate_limit(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ rate limiting (429 –æ—à–∏–±–∫–∞)."""
        with self._lock:
            self._rate_limit_detected = True
            self._last_429_time = time()
            self._current_delay = self.base_delay * 3

        logger.warning(
            f"üö® Rate limit detected! Slowing down (delay: {self._current_delay}s)"
        )

    def _download_single_image(self, url: str, index: int) -> Dict[str, Any]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å retry –ª–æ–≥–∏–∫–æ–π.

        :param url: URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        :param index: –ò–Ω–¥–µ–∫—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
        :return: –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º {success: bool, filename: str|None, url: str, attempts: int}
        """
        attempts = 0
        last_error = None

        for attempt in range(1, self.max_retries + 1):
            attempts = attempt

            try:
                # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º
                if attempt > 1:
                    # Exponential backoff –¥–ª—è retry
                    backoff_delay = self.retry_delay * (2 ** (attempt - 2))
                    sleep(backoff_delay)
                else:
                    self._adaptive_delay()

                # Deterministic proxy assignment: use pool by round-robin if provided
                assigned_proxies = None
                try:
                    if self.proxy_pool:
                        assigned_proxies = self.proxy_pool[(index - 1) % len(self.proxy_pool)]
                except Exception:
                    assigned_proxies = None

                # –ó–∞–≥—Ä—É–∑–∫–∞ (download_func may accept proxies kw or session kw)
                proxy_index = None
                if self.proxy_pool:
                    try:
                        proxy_index = (index - 1) % len(self.proxy_pool)
                    except Exception:
                        proxy_index = None

                acquired = False
                if proxy_index is not None:
                    sem = self._proxy_semaphores.get(proxy_index)
                    if sem:
                        # shorter timeout to avoid long stalls
                        acquired = sem.acquire(timeout=5)

                try:
                    # Prefer calling download_func with proxies kw; fallback to positional call
                    try:
                        result = self.download_func(url, proxies=assigned_proxies)
                    except TypeError:
                        result = self.download_func(url)
                finally:
                    if acquired and proxy_index is not None:
                        sem = self._proxy_semaphores.get(proxy_index)
                        if sem:
                            try:
                                sem.release()
                            except Exception:
                                pass

                if result:
                    with self._lock:
                        self._downloaded += 1
                        current = self._downloaded
                        total = self._total

                    # –£–±–∏—Ä–∞–µ–º –ø–æ–¥—Ä–æ–±–Ω—ã–µ debug –ª–æ–≥–∏ - –≤–∞–∂–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ç–µ–ø–µ—Ä—å –≤ MangaBuilder

                    return {
                        'success': True,
                        'filename': result,
                        'url': url,
                        'attempts': attempts,
                        'index': index
                    }
                else:
                    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Ä–Ω—É–ª–∞ None - –≤–æ–∑–º–æ–∂–Ω–æ 404 –∏–ª–∏ –¥—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞
                    last_error = "Download returned None"

            except Exception as e:
                last_error = str(e)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ rate limiting
                if '429' in str(e) or 'too many requests' in str(e).lower():
                    self._handle_rate_limit()

                logger.warning(
                    f"‚ö†Ô∏è Attempt {attempt}/{self.max_retries} failed for image {index}: {e}"
                )

        # –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å
        with self._lock:
            self._failed += 1

        logger.error(
            f"‚ùå Failed to download image {index} after {attempts} attempts: {last_error}"
        )

        return {
            'success': False,
            'filename': None,
            'url': url,
            'attempts': attempts,
            'error': last_error,
            'index': index
        }

    def download_batch(self, urls: List[str], progress_callback: Optional[Callable[[int, int], None]] = None) -> List[Dict[str, Any]]:
        """
        –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –±–∞—Ç—á–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.

        :param urls: –°–ø–∏—Å–æ–∫ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        :param progress_callback: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π callback –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (downloaded, total)
        :return: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ [{success, filename, url, attempts, index}, ...]
        """
        if not urls:
            return []

        with self._lock:
            self._total = len(urls)
            self._downloaded = 0
            self._failed = 0

        # –£–±–∏—Ä–∞–µ–º debug –ª–æ–≥ - –≤–∞–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Ç–µ–ø–µ—Ä—å –≤ MangaBuilder

        results = []
        start_time = time()

        # –°–æ–∑–¥–∞—ë–º ThreadPoolExecutor —Å —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º workers
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏
            future_to_url = {
                executor.submit(self._download_single_image, url, idx): (url, idx)
                for idx, url in enumerate(urls, start=1)
            }

            # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–µ—Ä–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            for future in as_completed(future_to_url):
                url, idx = future_to_url[future]

                try:
                    result = future.result()
                    results.append(result)

                    # –í—ã–∑—ã–≤–∞–µ–º progress callback
                    if progress_callback:
                        with self._lock:
                            progress_callback(self._downloaded, self._total)

                except Exception as e:
                    logger.error(f"‚ùå Unexpected error processing image {idx}: {e}")
                    results.append({
                        'success': False,
                        'filename': None,
                        'url': url,
                        'attempts': 0,
                        'error': str(e),
                        'index': idx
                    })
                    with self._lock:
                        self._failed += 1

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        elapsed = time() - start_time
        with self._lock:
            downloaded = self._downloaded
            failed = self._failed
            total = self._total

        avg_speed = total / elapsed if elapsed > 0 else 0

        # –£–±–∏—Ä–∞–µ–º –ø–æ–¥—Ä–æ–±–Ω—ã–π –ª–æ–≥ - –≤–∞–∂–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ç–µ–ø–µ—Ä—å –≤ MangaBuilder

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É
        results.sort(key=lambda x: x['index'])

        return results
